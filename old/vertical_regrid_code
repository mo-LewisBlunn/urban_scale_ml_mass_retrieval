def vertically_interpolate_to_target_heights(cubelist_by_stream, target_heights, temp_out_dir, log_dir, job_script_template_path=None):
    """
    Offload vertical interpolation of cubes to SLURM jobs via sbatch.
    Each cube is saved to disk and submitted as a separate job.
    """
    target_heights = np.array(target_heights)
    interpolated_files = []
    new_cubelist_by_stream = {}

    os.makedirs(temp_out_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)

    for stream, cubelist in cubelist_by_stream.items():
        new_cubelist = iris.cube.CubeList()

        for i, cube in enumerate(cubelist):
            if cube.coords("model_level_number") and cube.coords("level_height"):
                input_path = os.path.join(temp_out_dir, f"{stream}_{i}_in.nc")
                output_path = os.path.join(temp_out_dir, f"{stream}_{i}_out.nc")
                log_path = os.path.join(log_dir, f"{stream}_{i}.log")

                iris.save(cube, input_path)

                # Write job script
                with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".sh") as script_file:
                    script_contents = f"""#!/bin/bash -l
#SBATCH --qos=normal
#SBATCH --mem=4G
#SBATCH --ntasks=1
#SBATCH --output={log_path}
#SBATCH --time=15

module load iris  # Ensure Iris is available in the job environment

python <<EOF
import iris
import numpy as np
from iris.analysis import Linear
from iris.coords import DimCoord, AuxCoord

cube = iris.load_cube("{input_path}")
target_heights = np.array({target_heights.tolist()})

interpolated = cube.interpolate([('level_height', target_heights)], Linear())

iris.save(interpolated, "{output_path}")
EOF
"""
                    script_file.write(script_contents)
                    script_path = script_file.name

                os.chmod(script_path, 0o755)
                subprocess.run(["sbatch", script_path])
                interpolated_files.append((stream, output_path))
            else:
                new_cubelist.append(cube)

        new_cubelist_by_stream[stream] = new_cubelist

    return new_cubelist_by_stream, interpolated_files



def wait_for_results(interpolated_files, timeout=600, check_interval=5):
    print("Waiting for interpolation jobs to complete...")
    start_time = time.time()

    while True:
        if all(os.path.exists(out_file) for _, out_file in interpolated_files):
            print("All interpolated files are ready.")
            break
        elif time.time() - start_time > timeout:
            raise TimeoutError("Timeout waiting for interpolation jobs.")
        time.sleep(check_interval)
        


def reload_regrid_cubes(cubelist_by_stream, interpolated_files):
    for stream, path in interpolated_files:
        cube = iris.load_cube(path)
        cubelist_by_stream[stream].append(cube)
    return cubelist_by_stream
